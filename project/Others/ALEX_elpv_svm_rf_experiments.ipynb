{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5AowJ0ftFOrs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shady\\anaconda3\\envs\\COMP9517\\lib\\site-packages\\requests\\__init__.py:114: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (2.3.0)/charset_normalizer (None) doesn't match a supported version!\n",
            "  RequestsDependencyWarning,\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm # for loading progress\n",
        "\n",
        "import seaborn as sns #  for plotting\n",
        "import sys\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC,LinearSVC, LinearSVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#from KOC.koc.src.elpv_reader import load_dataset\n",
        "\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wspo8ssKHp7B"
      },
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XlX4-TjAFq-u"
      },
      "outputs": [],
      "source": [
        "# Reduce the dataset while maintaining correct distributions of samples from the original\n",
        "def reduce_dataset(df, fraction=1.0):\n",
        "\n",
        "    if fraction == 1.0:\n",
        "        return df\n",
        "\n",
        "    sample_sizes = df.groupby(['type', 'proba']).size().mul(fraction).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "    # Create an empty DataFrame to store the reduced dataset\n",
        "\n",
        "    reduced_df = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "\n",
        "\n",
        "    # Iterate over each group and sample according to the calculated sample sizes\n",
        "\n",
        "    for (type_value, proba_value), size in sample_sizes.items():\n",
        "\n",
        "        # Filter the dataframe for the current group\n",
        "\n",
        "        group_df = df[(df['type'] == type_value) & (df['proba'] == proba_value)]\n",
        "\n",
        "        # Sample 'size' number of rows from the group\n",
        "\n",
        "        samples = group_df.sample(n=size, random_state=1) if size > 0 else pd.DataFrame()\n",
        "\n",
        "        # Append the samples to the reduced dataframe\n",
        "\n",
        "        reduced_df = pd.concat([reduced_df, samples])\n",
        "\n",
        "\n",
        "\n",
        "    return reduced_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UauUfVSpJGIA"
      },
      "outputs": [],
      "source": [
        "sys.path.append('../../elpv-dataset/utils')\n",
        "from elpv_reader import load_dataset\n",
        "images, probas, types = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YGbt83rgFgVw"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "img_ids = np.arange(images.shape[0])\n",
        "df = pd.DataFrame({'img_id': img_ids, 'type': types, 'proba': probas})\n",
        "reduced_df = reduce_dataset(df, 1.0) # reduce to 50% original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCOF4wuZGncI"
      },
      "source": [
        "# 1. Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-16N-AxGvVv"
      },
      "source": [
        "## 1.1 Keypoint Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvL2lFHeGyfX"
      },
      "source": [
        "### 1.1.1 Dense Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "djc9dg2BF4zw"
      },
      "outputs": [],
      "source": [
        "class DenseSampler:\n",
        "    def __init__(self, grid_size=55):\n",
        "        self.grid_size = grid_size\n",
        "\n",
        "    def detect(self, image):\n",
        "        assert image is not None\n",
        "        img_dim = image.shape[0]\n",
        "        n_cells_x = img_dim // self.grid_size\n",
        "        n_cells_y = img_dim // self.grid_size\n",
        "\n",
        "        # Calculate the centers of each grid cell as the keypoint\n",
        "        centers = tuple(cv.KeyPoint(x * self.grid_size + self.grid_size / 2, y * self.grid_size + self.grid_size / 2, self.grid_size)\n",
        "                       for y in range(n_cells_y) for x in range(n_cells_x))\n",
        "\n",
        "        return centers # cv.KeyPoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sY_4yTX_F9nF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Densley sampling image keypoints: 100%|██████████| 2624/2624 [00:00<00:00, 92046.82it/s]\n"
          ]
        }
      ],
      "source": [
        "dsampler = DenseSampler(grid_size=60) #ideal from paper\n",
        "image_keypoints = {i: dsampler.detect(images[i]) for i in tqdm(reduced_df['img_id'], desc=\"Densley sampling image keypoints\")}\n",
        "image_keypoints = {k: v for k, v in image_keypoints.items() if v} # remove any images where no kps are detected\n",
        "\n",
        "image_kp_offsets = {}\n",
        "\n",
        "offset = 0\n",
        "for img_id in img_ids:\n",
        "  kps = image_keypoints.get(img_id, None)\n",
        "  if kps:\n",
        "    num_kps = len(kps)\n",
        "    image_kp_offsets[img_id] = (offset, num_kps)\n",
        "    offset += num_kps\n",
        "total_descriptors = offset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T196gSaAHBnP"
      },
      "source": [
        "## 1.2 Feature description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bhhZj_lI9tp"
      },
      "source": [
        "### 1.2.1 SIFT descriptor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RZJGJqcWGXgT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total #descriptors: 65600 descriptor size: 128\n",
            "all_desc.shape (65600, 128)\n"
          ]
        }
      ],
      "source": [
        "sift = cv.SIFT_create()\n",
        "\n",
        "descriptor_size = sift.descriptorSize()\n",
        "print('total #descriptors:',total_descriptors, 'descriptor size:', descriptor_size)\n",
        "\n",
        "all_descriptors = np.empty((total_descriptors, 128), dtype=np.float64)\n",
        "\n",
        "for img_id, keypoints in image_keypoints.items():\n",
        "    start, num_desc = image_kp_offsets[img_id]\n",
        "    end = start + num_desc\n",
        "    #print('id, start:end', f'{img_id}, {start}:{end}')\n",
        "    all_descriptors[start: end, :] = sift.compute(images[img_id], keypoints)[1]\n",
        "\n",
        "#sift_descriptors = {k: sift.compute(images[k],v)[1] for k, v in image_keypoints.items()}p\n",
        "print('all_desc.shape', all_descriptors.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_KEXOwcHM28"
      },
      "source": [
        "# 2. Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZYrflHBRHN_D"
      },
      "outputs": [],
      "source": [
        "# Codebook creation\n",
        "\n",
        "def encode_descriptors(all_descriptors):\n",
        "    \"\"\"Creates the VLAD codebook  using subset clustering.\n",
        "        Descriptors for training samples only should be used.\"\"\"\n",
        "\n",
        "    D = {}\n",
        "    num_subsets = 5\n",
        "    m = num_subsets\n",
        "    subset_size = len(all_descriptors) // 4\n",
        "    k = 20 # 20 with subser // 20 best!! (5% of training data)\n",
        "\n",
        "    print(all_descriptors.shape)\n",
        "\n",
        "\n",
        "    for i in range(num_subsets):\n",
        "        subset_indices = np.random.choice(len(all_descriptors), subset_size, replace=False)\n",
        "        subset_descriptors = all_descriptors[subset_indices]\n",
        "        kmeans = MiniBatchKMeans(n_clusters=k, random_state=i, batch_size=256*24) # 256*#cores\n",
        "        kmeans.fit(subset_descriptors)# replace with only test set samples\n",
        "        D[i] = kmeans\n",
        "\n",
        "\n",
        "    def vlad_encode(descriptors):\n",
        "        \"\"\"a vlad encoding is return for the descriptors of a single image\"\"\"\n",
        "        d = descriptors.shape[1]\n",
        "\n",
        "        # encode the desctiptors for a single image into a vlad vector for each kmean subset\n",
        "        vlad_vector = []#np.empty((1, m*k*d))\n",
        "        pca = PCA(whiten=True)#, n_components=128)\n",
        "\n",
        "        p = 0.5\n",
        "\n",
        "        for idx, kmeans_ in D.items():\n",
        "            cluster_assignments = kmeans_.predict(descriptors)\n",
        "\n",
        "            vlad_vector_ = np.zeros((k, descriptors.shape[1]),)\n",
        "\n",
        "            for idx, cluster_idx in enumerate(cluster_assignments):\n",
        "                vlad_vector_[cluster_idx] += (descriptors[idx] - kmeans_.cluster_centers_[cluster_idx])\n",
        "\n",
        "            vlad_vector_ = np.sign(vlad_vector_) * np.abs(vlad_vector_) ** p\n",
        "            vlad_vector_ = normalize(vlad_vector_.reshape(1, -1), axis=1, norm='l2') # (1, Kd)\n",
        "            vlad_vector.append(vlad_vector_)\n",
        "\n",
        "\n",
        "        vlad_vector = np.hstack(vlad_vector)\n",
        "        vlad_vector = pca.fit_transform(vlad_vector.reshape(-1,1)) # (1, mKd)\n",
        "        vlad_vector = normalize(vlad_vector.reshape(1, -1), axis=1, norm='l2')\n",
        "\n",
        "        return vlad_vector\n",
        "\n",
        "    return vlad_encode\n",
        "\n",
        "class Descriptors:\n",
        "    def __init__(self, desc_offsets, all_descriptors, encoder):\n",
        "        self.desc_offsets = desc_offsets\n",
        "        self.all_descriptors = all_descriptors\n",
        "        self.encoder = encoder\n",
        "        self.encoder_is_init = False\n",
        "        #self.vlad_encode = encode_descriptors\n",
        "\n",
        "    def get_by_id(self, img_id):\n",
        "        off, num_desc = self.desc_offsets[img_id]\n",
        "        end = off + num_desc\n",
        "        return self.all_descriptors[off: end, :]\n",
        "\n",
        "    def get_by_ids(self, img_ids):\n",
        "        \"\"\"Returns:\n",
        "            descriptors grouped by the order of id list\n",
        "        \"\"\"\n",
        "        descs_by_id = []\n",
        "        for id in img_ids:\n",
        "            descs_by_id.append(self.get_by_id(id))\n",
        "        return descs_by_id\n",
        "\n",
        "    def init_encoder(self, all_train_descriptors):\n",
        "        self.encoder = self.encoder(all_train_descriptors)\n",
        "        self.encoder_is_init = True\n",
        "\n",
        "    def _get_vlad_vector(self, id):\n",
        "        if not self.encoder_is_init:\n",
        "            raise Exception(\"initiliase encoder first.\")\n",
        "\n",
        "        descriptors = self.get_by_id(id)\n",
        "        vlad_vector = self.encoder(descriptors)\n",
        "        return vlad_vector\n",
        "\n",
        "\n",
        "    def get_all_vlad_vectors(self, img_ids):\n",
        "        return np.vstack([self._get_vlad_vector(id) for id in img_ids])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdPqAaaaHzR4"
      },
      "source": [
        "# 3. Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFVZK6lQIpmD"
      },
      "source": [
        "## 3.1 SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Oy7PuFwEHbgr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49200, 128)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.79     377.0\n",
            "           1       0.64      0.51      0.56 219.00000000000006\n",
            "\n",
            "    accuracy                           0.71     596.0\n",
            "   macro avg       0.69      0.67      0.68     596.0\n",
            "weighted avg       0.71      0.71      0.70     596.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# RUN svm classifier\n",
        "\n",
        "\n",
        "#X = np.vstack(all_vlad_vectors) # The descriptors as VLAD vectors\n",
        "X = sorted(image_keypoints)\n",
        "#y = new_y # The y with all samples without any detected keypoints/descriptors removed\n",
        "y = reduced_df[reduced_df['img_id'].isin(image_kp_offsets.keys())].sort_index()['proba'].to_numpy()\n",
        " # The y with all samples without any detected keypoints/descriptors removed\n",
        "\n",
        "y_binary = np.where(y > 0, 1, 0)\n",
        "\n",
        "# weights are:\n",
        "# 1.0         (class 0) functional\n",
        "# 0.33,0.67,1 (class 1) defective\n",
        "# This is a binary classification problem\n",
        "sample_weights = np.where((y == 0) | (y == 1), 1, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(\n",
        "    X, y_binary,\n",
        "    sample_weights,   # the certainty of the class label\n",
        "    test_size=0.25,   # from the paper 75/25 split\n",
        "    random_state=42,\n",
        "    stratify=y_binary # ensure balanced functional/defective samples\n",
        "  )\n",
        "\n",
        "# Inverse proportion heuristic derived from King and Zeng (2001) from the paper\n",
        "class_weights = {\n",
        "    0: y_train.size / 2*np.sum(y_train == 0),\n",
        "    1: y_train.size / 2*np.sum(y_train == 1)\n",
        "}\n",
        "\n",
        "descriptors = Descriptors(image_kp_offsets, all_descriptors, encode_descriptors)\n",
        "X_train_descriptors = np.vstack(descriptors.get_by_ids(X_train))\n",
        "\n",
        "# ===============================================================================\n",
        "# Create the VLAD codebook with subsets of the descriptors training set\n",
        "# ===============================================================================\n",
        "descriptors.init_encoder(X_train_descriptors)\n",
        "\n",
        "# ===============================================================================\n",
        "# Create VLAD vector for each image in the training set\n",
        "# with its descriptors using the created codebook\n",
        "# ===============================================================================\n",
        "all_vlad_vectors = descriptors.get_all_vlad_vectors(X_train)\n",
        "\n",
        "# ===============================================================================\n",
        "# Initialize and train the SVM classifier using the vlad vectors created\n",
        "#  for each image\n",
        "# ===============================================================================\n",
        "clf = LinearSVC(class_weight='balanced', C=1)#, max_iter=10000)\n",
        "clf.fit(all_vlad_vectors, y_train, sample_weight=sw_train)\n",
        "\n",
        "# ===============================================================================\n",
        "# Create VLAD vector for each image in the test set\n",
        "# ===============================================================================\n",
        "all_vlad_vectors = descriptors.get_all_vlad_vectors(X_test)\n",
        "\n",
        "y_pred = clf.predict(all_vlad_vectors)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred, sample_weight=sw_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhyBJrTNIuGb"
      },
      "source": [
        "## 3.2 Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kYpDNYB5IxgG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49200, 128)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84     377.0\n",
            "           1       0.74      0.67      0.70 219.00000000000006\n",
            "\n",
            "    accuracy                           0.79     596.0\n",
            "   macro avg       0.78      0.77      0.77     596.0\n",
            "weighted avg       0.79      0.79      0.79     596.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = sorted(image_keypoints)\n",
        "#y = new_y # The y with all samples without any detected keypoints/descriptors removed\n",
        "y = reduced_df[reduced_df['img_id'].isin(image_kp_offsets.keys())].sort_index()['proba'].to_numpy()\n",
        " # The y with all samples without any detected keypoints/descriptors removed\n",
        "\n",
        "y_binary = np.where(y > 0, 1, 0)\n",
        "\n",
        "# weights are:\n",
        "# 1.0         (class 0) functional\n",
        "# 0.33,0.67,1 (class 1) defective\n",
        "# This is a binary classification problem\n",
        "sample_weights = np.where((y == 0) | (y == 1), 1, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(\n",
        "    X, y_binary,\n",
        "    sample_weights,   # the certainty of the class label\n",
        "    test_size=0.25,   # from the paper 75/25 split\n",
        "    random_state=42,\n",
        "    stratify=y_binary # ensure balanced functional/defective samples\n",
        "  )\n",
        "\n",
        "# Inverse proportion heuristic derived from King and Zeng (2001) from the paper\n",
        "class_weights = {\n",
        "    0: y_train.size / 2*np.sum(y_train == 0),\n",
        "    1: y_train.size / 2*np.sum(y_train == 1)\n",
        "}\n",
        "\n",
        "descriptors = Descriptors(image_kp_offsets, all_descriptors, encode_descriptors)\n",
        "X_train_descriptors = np.vstack(descriptors.get_by_ids(X_train))\n",
        "\n",
        "# ===============================================================================\n",
        "# Create the VLAD codebook with subsets of the descriptors training set\n",
        "# ===============================================================================\n",
        "descriptors.init_encoder(X_train_descriptors)\n",
        "\n",
        "# ===============================================================================\n",
        "# Create VLAD vector for each image in the training set\n",
        "# with its descriptors using the created codebook\n",
        "# ===============================================================================\n",
        "all_vlad_vectors = descriptors.get_all_vlad_vectors(X_train)\n",
        "\n",
        "# ===============================================================================\n",
        "# Initialize and train the SVM classifier using the vlad vectors created\n",
        "#  for each image\n",
        "# ===============================================================================\n",
        "#clf = LinearSVC(class_weight='balanced', C=1)#, max_iter=10000)\n",
        "clf = RandomForestClassifier(class_weight='balanced')\n",
        "clf.fit(all_vlad_vectors, y_train, sample_weight=sw_train)\n",
        "\n",
        "\n",
        "# ===============================================================================\n",
        "# Create VLAD vector for each image in the test set\n",
        "# ===============================================================================\n",
        "all_vlad_vectors = descriptors.get_all_vlad_vectors(X_test)\n",
        "\n",
        "y_pred = clf.predict(all_vlad_vectors)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred, sample_weight=sw_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
